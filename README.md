# ğŸ­ Deepfake Detection System

<div align="center">

![Deepfake Detection](https://img.shields.io/badge/AI-Deepfake%20Detection-red?style=for-the-badge&logo=artificial-intelligence)
![PyTorch](https://img.shields.io/badge/PyTorch-EE4C2C?style=for-the-badge&logo=pytorch&logoColor=white)
![Python](https://img.shields.io/badge/Python-FFD43B?style=for-the-badge&logo=python&logoColor=blue)

</div>

---

## ğŸŒŸ What's This About?

Welcome to our **Advanced Deepfake Detection System** - a deep model that combines Vision Transformers with Cross-Modal Fusion to distinguish between real and AI-generated fake images! ğŸ•µï¸â€â™‚ï¸ Built for the **SP Cup Competition 2024**, this hybrid architecture achieved outstanding performance across multiple datasets.

## ğŸ§  Model Architecture

Our innovative approach combines multiple state-of-the-art techniques:

### ğŸ”§ Core Components
- **ğŸ¯ MViT (Multiscale Vision Transformer)**: Custom MViT transformer blocks with multi-head attention and Scales
- **ğŸŒŠ CMF (Cross-Modal Fusion) Block**: Integrates RGB, frequency spectrum, and texture features
- **ğŸ“Š ConvNeXT Feature Extractor**: Pre-trained backbone for robust feature extraction
- **ğŸ­ Multi-Modal Analysis**: Processes RGB images, Fourier spectrum, and Local Binary Patterns (LBP)

### ğŸ—ï¸ Architecture Details
```
Input Image (224x224x3)
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     MViT-CMF Repeated Blocks        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ MViT Block  â”‚â†’ â”‚ CMF Block   â”‚   â”‚
â”‚  â”‚ - Patch     â”‚  â”‚ - RGB       â”‚   â”‚
â”‚  â”‚ - Attention â”‚  â”‚ - Spectrum  â”‚   â”‚
â”‚  â”‚ - Transform â”‚  â”‚ - LBP       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        Feature Fusion               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ MViT-CMF    â”‚  â”‚ ConvNeXT    â”‚   â”‚
â”‚  â”‚ Features    â”‚â†’ â”‚ Features    â”‚   â”‚
â”‚  â”‚ (30,000)    â”‚  â”‚ (1,024)     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
FC Layers (31,024 â†’ 1,000 â†’ 128 â†’ 2)
    â†“
Real/Fake Classification
```

## ğŸ“Š Performance Highlights

<div align="center">

| ğŸ¯ Metric | ğŸ“ˆ Training | ğŸ” Validation | ğŸ§ª Testing (DeepWild) |
|-----------|-------------|---------------|----------------------|
| **Accuracy** | `98.49%` ğŸ”¥ | `97.94%` âœ¨ | `91.20%` ğŸ’ª |

</div>

## ğŸª Training Dataset

Our model was trained on a diverse combination of datasets:
- ğŸ† **SP Cup Competition 2024 Dataset** - Competition-grade deepfake samples
- ğŸŒŸ **CelebHQ Dataset** - High-quality celebrity images
- ğŸ­ **Tested on DeepWild Fake Dataset** - Real-world deepfake evaluation

## ğŸ—‚ï¸ Project Structure

```
ğŸ“ deepfake-detection/
â”œâ”€â”€ ğŸ train_script.py          # Main training script
â”œâ”€â”€ ğŸ” validate.py              # Validation & testing script
â”œâ”€â”€ ğŸ§  models.py                # MViT-CMF model architecture
â”œâ”€â”€ ğŸ”§ utils.py                 # Utility functions
â”œâ”€â”€ ğŸ’¾ best_model.pth           # Trained model weights
â”œâ”€â”€ ğŸ“Š validation_confusion_matrix.png
â””â”€â”€ ğŸ“š README.md                # You're here! ğŸ‘‹
```

## ğŸš€ Quick Start

### 1ï¸âƒ£ Installation

First, make sure you have Python 3.8+ installed, then install the required packages:

```bash
pip install torch torchvision tqdm matplotlib seaborn scikit-learn numpy opencv-python scikit-image
```

### 2ï¸âƒ£ Training the Model

```bash
python train_script.py
```

**What happens during training:**
- ğŸ”„ Loads and preprocesses your dataset
- ğŸ§  Initializes the MViT-CMF classifier model
- ğŸ“ˆ Trains for 100 epochs with early stopping
- ğŸ’¾ Saves the best model based on validation accuracy
- ğŸ“Š Generates training plots and metrics

### 3ï¸âƒ£ Validating the Model

```bash
python validate.py
```

**Validation features:**
- ğŸ¯ Comprehensive accuracy metrics
- ğŸ“Š Confusion matrix visualization
- ğŸ“‹ Detailed classification report
- ğŸ­ Per-class performance analysis

## ğŸ”§ Model Architecture Details

### ğŸ¯ MViT Block Features:
- **Patch Embedding**: Converts 224Ã—224 images into 16Ã—16 patches
- **Multi-head Attention**: 8-head self-attention mechanism
- **Positional Encoding**: Spatial position information preservation
- **Residual Connections**: Skip connections for gradient flow

### ğŸŒŠ CMF Block Features:
- **Multi-modal Input**: RGB + Frequency Spectrum + LBP textures
- **Fourier Analysis**: 2D FFT for frequency domain analysis
- **Local Binary Patterns**: Texture feature extraction
- **Cross-Modal Attention**: Fusion of different feature modalities

### ğŸ“Š Feature Extraction:
- **ConvNeXT Backbone**: Pre-trained feature extractor (1,024 features)
- **MViT-CMF Features**: Custom features (30,000 dimensions)
- **Feature Fusion**: Concatenated multi-scale representations

## ğŸ“ˆ Training Configuration

| Parameter | Value | Description |
|-----------|-------|-------------|
| ğŸ¯ **Batch Size** | `32` | Images per training batch |
| ğŸ“š **Learning Rate** | `1e-4` | Adam optimizer learning rate |
| ğŸ”„ **Epochs** | `100` | Maximum training epochs |
| ğŸ§  **MViT-CMF Blocks** | `6` | Number of transformer-fusion blocks |
| ğŸ“Š **Max Samples** | `100,000` | Maximum training samples |
| ğŸ­ **Patch Size** | `16Ã—16` | Vision transformer patch size |
| âš¡ **Embedding Dim** | `256` | Transformer embedding dimension |

## ğŸ¨ Key Features

- âœ… **Hybrid Architecture**: Combines transformers with frequency analysis
- ğŸ”„ **Multi-Modal Processing**: RGB, spectrum, and texture analysis
- ğŸ“Š **Advanced Feature Fusion**: ConvNeXT + MViT-CMF integration
- ğŸ’¾ **Robust Training**: Early stopping and model persistence
- ğŸ“ˆ **Comprehensive Metrics**: Detailed performance visualization
- ğŸ¯ **Cross-Dataset Validation**: Tested on multiple deepfake datasets
- ğŸ§  **Attention Mechanisms**: Self-attention for long-range dependencies

## ğŸ­ Usage Examples

### Basic Validation
```python
from validate import validate_model

# Validate on default test set
results = validate_model('best_model.pth')
print(f"Accuracy: {results['accuracy']:.2f}%")
```

### Custom Dataset Validation
```python
from validate import validate_on_custom_dataset

# Test on your own dataset
results = validate_on_custom_dataset(
    model_path='best_model.pth',
    custom_test_path='path/to/your/test/data'
)
```

### Model Architecture Info
```python
from models import classifier_block

# Initialize model
model = classifier_block(num_classes=2, n_blocks=6)
print(f"Total parameters: {sum(p.numel() for p in model.parameters())}")
```

## ğŸ“Š Results Visualization

The validation script automatically generates:
- ğŸ¨ **Confusion Matrix**: Visual representation of predictions
- ğŸ“ˆ **Performance Metrics**: Precision, Recall, F1-Score
- ğŸ¯ **Class-wise Accuracy**: Real vs Fake detection rates
- ğŸŒŠ **Feature Analysis**: Multi-modal feature importance

## ğŸ› ï¸ Customization

### Modify Model Architecture:
Edit `models.py` to adjust:
- ğŸ§  Number of MViT-CMF blocks (`n_blocks`)
- ğŸ¯ Transformer embedding dimensions
- ğŸŒŠ CMF block configurations
- ğŸ“Š Feature fusion strategies

### Training Parameters:
Edit `train_script.py` to adjust:
- ğŸšï¸ Learning rate and optimizer settings
- ğŸ“¦ Batch size and data loading
- ğŸ”„ Number of epochs and early stopping
- ğŸ’¾ Model saving strategies

### Add New Datasets:
Update the data paths in both training and validation scripts to point to your datasets.

---

<div align="center">

**ğŸ­  Happy Deepfake Detecting!  ğŸ•µï¸â€â™‚ï¸**

*Made with â¤ï¸  from NiceGuy*

[![GitHub](https://img.shields.io/badge/GitHub-100000?style=for-the-badge&logo=github&logoColor=white)](https://github.com/yourusername/deepfake-detection)
[![Python](https://img.shields.io/badge/Python-3.8+-blue?style=for-the-badge&logo=python&logoColor=white)](https://python.org)
[![PyTorch](https://img.shields.io/badge/PyTorch-Latest-red?style=for-the-badge&logo=pytorch&logoColor=white)](https://pytorch.org)

</div>